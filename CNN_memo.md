CNNに関するメモ

CNNを特徴づけるのは畳み込み処理とプーリング処理

畳み込み処理では、カーネルという小さい正方形領域の配列を用意する。このカーネルを画像の左上から右下にかけてスライドさせながら、カーネルの値と画像の値を掛け合わせて合計値を求める。この合計値を出力画像の左上の画素値とする。この処理を画像の右下まで繰り返す。この処理を畳み込み処理という。

一方でプーリング処理とは、画像の一部の領域をまとめて一つの画素値にする処理である。例えば、2×2の領域をまとめて平均値を求めるであったり、最大値を出力したりする。
この処理をプーリング処理という。

畳み込み処理は１画素ずつずらして処理することが多いが、プーリング処理は重なる領域をとらないようにずらすのが普通である。

CNNのモデルは、畳み込み層とプーリング層を繰り返し、最後に全結合層を置くことが多い。

PyTorchのレイヤー関数において、畳み込み処理は`nn.Conv2d`、プーリング処理は`nn.MaxPool2d`を用いる。
畳み込み関数は、関数の内部にパラメータを持つが、プーリング関数は単なる演算である。
CNNでは、これまでのレイヤー関数にはない１階化関数というものがある。これは、チャネル、タテ、ヨコと３階の広がりを持つ畳み込み処理やプーリング処理の出力を
ヨコ一列のベクトルに変換する関数である。これは、分類モデルでは最終的な出力が１階テンソルなので、どこかで必要な処理になる。
この畳込み関数に対応するのが`nn.Flatten`である。

過学習への対応策

○ドロップアウト
ドロップアウトとは、学習時にランダムにノードを選び、そのノードを無視して学習することである。これにより、ノード間の依存関係が弱くなり、過学習を防ぐことができる。
訓練時には、ドロップアウトを行うが、テスト時にはドロップアウトを行わない。これは、テスト時には全てのノードを使って予測を行うことで、より精度の高い予測を行うためである。

○Batch Normalization
Batch Normalizationとは、ミニバッチごとに正規化を行うことである。これにより、学習が早くなるというメリットがある。

○Data Augmentation(データ拡張)
Data Augmentationとは、訓練データを加工してデータ数を増やすことである。例えば、画像の場合、画像を回転させたり、反転させたり、明るさを変えたりすることで、データ数を増やすことができる。




